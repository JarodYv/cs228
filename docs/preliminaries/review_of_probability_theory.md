# 概率论回顾

首先让我们回顾一下概率论的一些概念，这部分所有的材料都改编自[CS229 - 概率论课程笔记](http://cs229.stanford.edu/section/cs229-prob.pdf)。

## 1. 概率基础

为了定义集合上的概率，我们需要一些基本元素。

**样本空间 $ \Omega $**: 随机实验所有结果的集合。其中，每个结果 $\omega \in \Omega$ 都可以被认为是实验结束时真实世界状态的完整描述。

**事件集（或事件空间）$ F $**: 元素 $A \in F$（称之为事件）是 $\Omega$ 的子集的集合。（例如，$A \subseteq \Omega$ 是实验可能结果的集合）。

**概率测度**: 一个满足如下性质的函数 $P : F \to \Re$

* 对于任意 $A \in F$, $P(A) \geq 0$
* 如果 $A_1, A_2, \dotsc$ 是不相交事件（即 $A_i \cap A_j = \emptyset$，其中 $i \neq j$），那么 $P(\bigcup_i A_i) = \sum_i P(A_i)$
* $P(\Omega) = 1$

这三个性质被称为概率公理。

举例：考虑抛六面骰子的事件。样本空间为 $\Omega = \{1, 2, 3, 4, 5, 6\}$。 我们可以在此样本空间上定义不同的事件空间。
例如，最简单的事件空间是平凡事件空间 $F = \{\emptyset, \Omega\}$。另一个事件空间是 $ \Omega $ 的所有子集的集合。
对于第一个事件空间，满足上述要求的唯一概率测度为 $P(\emptyset) = 0, P(\Omega) = 1$
对于第二个事件空间，一个有效的概率度量是将事件空间中每个集合的概率分配为 $\frac{i}{6}$，其中 $i$ 是该集合的元素数；
例如：$P(\{1, 2, 3, 4\}) = \frac{4}{6}$ 和 $P(\{1, 2, 3\}) = \frac{3}{6}$。

#### **性质**

- $A \subseteq B \implies P(A) \leq P(B)$
- $P(A \cap B) \leq \min(P(A), P(B))$
- **联合约束:** $P(A \cup B) \leq P(A) + P(B)$
- $P(\Omega - A) = 1 - P(A)$
- **全概率法则:** 如果 $A_1, \dotsc, A_k$ 是一组不相交的事件，即 $\bigcup^k_{i=1} A_i = \Omega$, 那么 $\sum^k_{i=1} P(A_i) = 1$

### 1.1 条件概率

设 $B$ 是非零概率的事件。给定 $B$ 的情况下任意事件 $A$ 的条件概率为：

$$ P(A \mid B) = \frac {P(A \cap B)}{P(B)} $$

换句话说，$P(A \mid B)$ 是观察事件B发生后事件A的概率度量。

### 1.2 链式法则

设 $S_1, \dotsc, S_k$ 为事件，$P(S_i) >0$，则链式法则描述如下：

$$
\begin{align*}
& P(S_1 \cap S_2 \cap \dotsb \cap S_k) \\
&= P(S_1) P(S_2 | S_1) P(S_3 | S_2 \cap S_1 ) \dotsb P(S_k | S_1 \cap S_2 \cap \dotsb \cap S_{k-1})
\end{align*}
$$

当 $k=2$ 时，上面的公式就是条件概率公式：

$$ P(S_1 \cap S_2) = P(S_1) P(S_2 | S_1) $$

一般来说，链式规则是通过多次应用条件概率的定义而导出的，例如：

$$
\begin{align*}
& P(S_1 \cap S_2 \cap S_3 \cap S_4) \\
&= P(S_1 \cap S_2 \cap S_3) P(S_4 \mid S_1 \cap S_2 \cap S_3) \\
&= P(S_1 \cap S_2) P(S_3 \mid S_1 \cap S_2) P(S_4 \mid S_1 \cap S_2 \cap S_3) \\
&= P(S_1) P(S_2 \mid S_1) P(S_3 \mid S_1 \cap S_2) P(S_4 \mid S_1 \cap S_2 \cap S_3)
\end{align*}
$$

### 1.3 独立性

如果 $P(A \cap B) = P(A)P(B)$，则称这两个事件独立，或等价于 $P(A \mid B) = P(A)$。直观感觉，如果事件 $A$ 和 $B$ 独立，
意味着对 $B$ 的观测不影响 $A$ 的概率。

## 2. 随机变量

考虑如下实验：我们翻转10个硬币，我们想知道出现正面的硬币数量。这里，样本空间 $\Omega 的元素是长度为10由头和尾组成的序列。
例如 $\omega_0 = \langle H, H, T, H, T, H, H, T, T, T \rangle \in \Omega$。
然而在实践中，我们通常不关心获得任何特定序列的头和尾的概率。相反，我们通常关心结果的实函数，例如10次抛投中出现的正面的次数，或连续出现反面的次数。
在某些技术场景下，这些函数被称为 **随机变量**。

随机变量更严格的定义是：随机变量 $X$ 是一个函数 $X : \Omega \to E$，其中 $E$ 是某可度量空间。
通常，我们使用大写字母 $X(\omega)$ 表示随机变量，或简写为 $X$(其中隐含了对随机结果 $\omega$ 的依赖)。
我们使用小写字母 $x$ 表示随机变量的值。因此 $X = x$ 表示我们将值 $x \in E$ 复制给随机变量 $X$。

举例：在我们上面的实验中，假设 $X(\omega)$ 是一系列抛投 $\omega$ 中正面出现的次数。
假定只抛投10个硬币，$X(\omega)$ 只能取有限个值，因此称为离散随机变量。 
此时，与随机变量 $X$ 关联的集合取某个特定值 $k$ 的概率为 $P(X = k) := P(\{\omega : X(\omega) = k\})$

举例：假设 $X(\omega)$ 是表示放射性粒子衰变所需的时间的随机变量。在本例中，$X(\omega)$ 有无穷多个可能值，因此称其为连续随机变量。
我们记 $X$ 取两个实数 $a$ 和 $b$ ($a \lt b$)之间的概率为 $P(a \leq X \leq b) := P(\{\omega : a \leq X(\omega) \leq b\})$

当描述随机变量具有特定值的事件时，我们通常用**指示函数** $\mathbf{1}\{A\}$，其中当事件 $A$ 发生时取值为1，反之取值为0。例如，对随机变量 $X$

$$
    \mathbf{1}\{X > 3\} = \begin{cases}
    1, & \text{if }X > 3 \\
    0, & \text{otherwise}
    \end{cases}
$$

### 2.1 累积分布函数

### 2.2 概率质量函数

### 2.3 概率密度函数

### 2.4 期望

### 2.5 方差

### 2.6 一些常见的随机变量

## 3. 双随机变量

### 3.1 联合分布和边缘分布

### 3.2 联合概率质量函数和边缘概率质量函数

### 3.3 联合概率密度函数和边缘概率密度函数

### 3.4 条件概率分布

### 3.5 链式法则

### 3.6 贝叶斯法则

### 3.7 独立性

### 3.8 期望和协方差

